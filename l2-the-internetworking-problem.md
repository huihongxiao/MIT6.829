# L2-The Internetworking Problem

英文原文：[https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-829-computer-networks-fall-2002/lecture-notes/L2Internetworking.pdf](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-829-computer-networks-fall-2002/lecture-notes/L2Internetworking.pdf)

## Overview

这节课会来看将不同网络互联在一起会有哪些问题。我们会学习互联网的设计原则，IP，互联网尽力而为（best-effort）的服务模型，它的设计和协议准则。

之后我们讨论IP和TCP的区别，并学习TCP是如何完成可靠数据传输。我们会看TCP的ACK机制，以及两种形式的丢包重传：时间驱动（timer-driven）和数据驱动（data-driven）。前者依赖于预估连接的round-trip time（RTT）来设置超时，而后者依赖于接收到数据流中更靠后的包来避免等待超时。数据驱动重传的例子包括了快速重传（fast retransmission）和选择性确认（selective acknowledgment SACK）。

## 1 网络互联的问题：许多不同类型的网络

上一节课，我们讨论了packet switching的原理，并且设计了一种方案来将LAN连接在一起。这里的核心在于一个叫做switch的设备，它会在不同的LAN之间转发packet。

尽管这样的网络可以工作，并且也很常见，它并不能用来构建一个全球的数据网络基础设施，它有两个主要的缺陷：

1. 它不能容纳异构性
2. 它并不能扩展到大规模网络

以上每一点都值得讨论。首先以太网绝不是世界上唯一的链路层技术，实际上，在以太网之前，packet在其他诸如无线射频，卫星信号，电话线等链路上传输。其次，以太网也通常不适用于几百公里的长距离传输。各种新的数据链路层技术一直在出现，并且会持续出现，而我们的目标就是确保任何新的数据链路层技术都可以接入到全球数据网络基础设施中。这就是容纳网络异构性的目标。

我们在[L1](l1-packet-switching.md#4.-yi-ge-li-zi-lan-switching)学习的LAN switching要求switch存储网络中每个host（实际上是每个网卡）的状态，如果switch中没有目的地址的状态，它会退而求其次将packet广播到整个网络中的所有链路上。这个在中等规模的主机数和链路数上都无法工作。

所以，网络互联的问题或许可以这样描述：设计个可扩展的网络基础设施，它能互联多个不同的小的网络，可以差异很大的网络上的主机之间能传递packet。

有关网络的差异，包含以下例子：

* **网络地址**。每个网络可能有自己地址格式。例如，以太网使用6个字节作为地址，而电话使用10位数字作为地址。
* **带宽和延时**。带宽可能会从几个bit/s到几个Gb/s，中间的跨度会有几个量级。类似的，延时也可能从几个微秒到几秒。
* **包大小**。不同网络的最大包尺寸可能会不同。
* **丢包率**。不同网络的丢包率和丢包模式都不相同。
* **路由模式**。不同网络的路由模式可能不同。例如射频网络的路由协议与有线网的路由协议就不一样。

从规模角度考虑，我们的目标就是尽可能的减少由switch维护的状态，和减少由控制流量消耗的带宽（例如路由信息，定期广播的消息等）。

### 1.1 Gateway

通过叫做gateway的设备可以帮助不同网络之间互联。Gateway可以连接具备不同特性的网络并在它们之间传递packet。至少存在两种连接方式可以连接不同的网络：翻译（translation）和统一的网络层（a unified network layer）。

基于翻译的网关会尽可能无感的，通过将packet header和协议从一个网络翻译到另一个网络来工作。这里的例子有OSI X.25/X.75 协议。翻译存在的主要问题包括：

* **功能缺失**。当翻译成另一种网络技术时，原有网络技术的功能（甚至是bug）不能被保留。对于用户来说，原有的一些假设就不成立了，因为一个特定的功能经过翻译之后就不再可用了。
* **差的扩展性**。翻译通常在需要互联的网络数较少，且其中每个网络也相对较小的场景下才能工作。它的扩展性较差因为翻译需要的信息与需要互联的网络数成平方的关系。这种方法被认为不能在大的互联网络中工作（值得注意的是，广泛部署的NAT网关使得互联网的一部分看起来像是翻译网关）。

### 1.2 互联网设计原则

互联网的设计者很早就发现了翻译的缺陷，并且认为正确的方法是在所有网络中标准化一些关键属性，并且定义少量的特性，让所有想连接到互联网的主机和网络都必须实现。

现在我们在回顾互联网协议时，已经可以识别并总结出藏在其中一些重要的设计原则。我们可以将这些原则分为两类：通用性（universality）和健壮性（robustness）。

#### 通用性原则

* IP-over-everything。所有的网络和主机都必须实现一个标准的网络协议 --- IP，也就是Internet Protocol。所有的网络和主机，如果想要能够从任意地址访问到，必须实现一个标准的定义好的地址规范。这样就可以避免翻译带来的扩展性问题，并且gateway也更容易实现了。
* 尽力而为的服务模型。gateway内部架构变得简单的一个结果就是服务模型变成了尽力而为。所有的packet都被同等对待，并且大多数时候不需要恢复网络中的丢包。这种定义好的简单的模型是互联网架构能够达到超大规模的主要原因。
* 端到端设计模式。这种设计模式是在最初的TCP/IP模型之后很久才总结出来，现在已经设计到互联网设计哲学的方方面面中了。TCP/IP的分层架构可以使得网络的内部变得简单，并且将所有复杂的机制例如稳定性，拥塞控制等放到终端主机，并且可以在主机上实现的更彻底。早期的设计（CK74）将TCP和IP一起实现在终端主机和gateway中，现在TCP和IP的分离，并将TCP从gateway中移除，是互联网变革的一个重要步骤。

#### 健壮性原则

* soft-state。大部分维护在gateway中的状态都是soft-state，就算它的数量很多或者被破坏了，也可以很容易的更新。Routing table就是一个很好的例子，gateway使用routing table来决定如何转发packet，而定期的路由更新避免了需要在router中实现复杂的错误处理程序。这样，gateway和路由协议被设计成在它们的常规操作中来客服故障，而不是在出错的时候需要特殊的机制。
* [fate sharing](https://en.wikipedia.org/wiki/Fate-sharing#:\~:text=Fate%2Dsharing%20is%20an%20engineering,was%20defined%20by%20David%20D.)。当一个主机与另一个主机通讯时，通讯对应的状态维护在系统中。在互联网，这里的关键状态在两个（或者多个）通讯主体中共享，而不会被网络中其他主机共享。如果一个终端主机故障了，其他主机的通讯状态也是故障，这样这些通讯主体共享了命运。如果一个gateway对于一个一条路由出现故障，端到端的通讯不会出现故障（注，这里应该是假设存在冗余线路），gateway中的状态是软的，并且gateway并不与终端主机共享命运。这与OSI X.25有明显的区别，在X.25中，gateway会维护硬的连接状态，并且终端主机会与gateway共享命运。
* 保守的发送/自由的接收（conservative-transmission/liberal reception）。”在发送的时候保守，在接收的时候自由。“这个针对网络协议的准则明显的增加了系统的健壮性。当一些从未交谈过的人共同编码一个大型系统时，这个原则尤其重要。甚至对于为一个规范写代码来说，这也是重要的，因为像英语一样的语言可能是模糊的，并且规范也会随时间变化。这个原则的一个例子体现在TCP协议中，一个TCP的发送端可能会收到一个它从来没有发送过packet的ACK。最差的反应是崩溃，因为发送端没有准备好接收它不曾预期的东西。但是这是错误的，现实中会悄悄的丢弃这个ACK，并看看从peer会来其他的数据。类似的，如果一个发送端发送一个带有非标准option的packet，它应该在协商之后才这么做。

### 1.3 互联网缺点

互联网并非没有缺点，很多缺点都是其最初设计目标的结果。

* 它的架构基本上依赖终端系统的可信赖性。它并没有考虑恶意终端系统的可能性，也没有考虑如何构建一个值得信赖的网络。
* 贪婪的发送端并没有较好的处理（特殊的用户，故障或者恶意的实现）。TCP可以很好的共享带宽，但是越来越多的流量并不是TCP。
* 在很长一段时间内，安全问题并没有像现在一样被重视。
* 较弱的审计和计费工具。这其实是最初的目标之一，但是并没有设计太多。
* 管理工具并不特别成熟。
* 增量部署。并不是一个基础的缺点，但是需要被每个协议设计者认识到。

### 1.4 互联网协议标准流程

互联网基础设置持续发展的一个有趣的方面是，标准设立和开发的过程。总的来说，这已经称为了一个非常成功的社会工程学的实践，来自许多不同组织的人朝着共识努力。IETF（Internet Engineering Task Force），一个自发的组织，是设立标准的主体。它会每4个月，按照working group的结构开一次会。这些working group从开始到终止通常都存活少于2年。互联网标准被记录在RFC（Request For Comments），并由IETF发布。可以查看http://www.ietf.org/获取更多信息。

Working group通过电子邮件完成大量的工作，并且对所有感兴趣的人开放。大体上来说，基于提案的投票是避免的，这里的流程喜欢”大体一致“。过去对于一个协议需要至少两个独立的实现，但是现在看起来这个要求被忽略了。

## 2 TCP/IP的起源

Cerf和Kahn在他们1974年的[论文](https://www.cs.princeton.edu/courses/archive/fall06/cos561/papers/cerf74.pdf)中描述了他们对网络互联问题的解决方案。这份早期的工作明显有巨大的影响，这就是尽管今天的互联网协议的实现细节非常不同，我们仍然要学习它的原因。论文中的一些设计原则保留至今。另外，这是一篇极好的论文，它呈现了一个具备足够细节的设计，感觉上一个人可以通过代码将它描述的规范实现出来。

下面是它们解决方案的关键点：

* gateway。不在gateway上做翻译。
* IP over everything
* 每个网络的内部属性可以不相同，但是整个互联网的地址格式需要是统一的。
* 统一的packet header。
* Gateway在必要的时候执行分片，终端主机负责重新组装packet。
* TCP：进程通过TCP进行通信，TCP是一个可靠的顺序的字节流协议。实际上，他们提出用TCP来完成分片的组装（而不是现在在接收端的IP层完成组装）。TCP和IP紧密的结合在一起，过了好几年才逐渐分开。
*   他们花费了很多时间来确定同一组主机上的多个进程如何通信。他们考虑了两个选项：



    1. 对于多个TCP segment使用相同的IP packet
    2. 对于不同的TCP segment使用不同的IP packet

    他们并没有考虑在一组主机间建立多个TCP连接！
* 第2个选项更好，因为它更容易复用，且在第1个选项中更难处理乱序的packet。
* 多路复用的key是端口号（一般一个进程对应一个端口）
* TCP基于字节流。
* 滑动窗口，基于累积ACK的ARQ协议（同时带有timeout）以达到可靠性和流控。类似于CYCLADES和ARPANET协议。
* 基于窗口的流控。可以是下进程粒度的流控。
* I/O处理，TCB（Transmit Control Block）的实现细节和建议。
* 第一次提出连接建立和释放的机制（虽然之后经过大幅修改才到了今天的样子）。
* 在审计的问题上错误较大（问题比他们预测的要难得多）。
* 一句话总结：一篇非常好的论文，具备了一个非常重要的互联网协议的细节。细节多到可以实际实现出来这个协议，但同时又不是一个枯燥的文档。

## 3. 今天的TCP/IP: IPv4

IP协议以及其地址策略最重要的部分在于，它是为大规模场景设计的。这是通过一个简单的想法实现的：IP地址并不是任意的，而是表明了它们在网络拓扑中的位置。这使得地址可以聚合在一起，并且维护在路由表中，最终达到一个层级的结构。激进的路由聚合使得当网络规模变大时，路由表的状态伸缩性较好。

### 3.1 地址

当IP协议的第4版1981年在RFC791中确定，地址被定为32bit长。这时，地址被分为不同的类，各种组织可以获取属于某一类的地址集合。在不同的分类中，地址的前半部分bit对应网络地址，后半部分bit对应主机地址。A类地址第一个bit为0，后面7个bit为网络地址，再后面24个bit为主机地址（例如，MIT拥有A类地址18/8）。B类地址前两个bit为10，后面14个bit为网络地址，最后16bit为主机地址。C类地址以bit 110开头，后面21bit为网络地址，最后8bit为主机地址。D类地址用于IP组播，它们以bit 1110开始，并使用剩下的28bit作为组播组地址。以bit 1111开头的地址被保留做实验用。

这种网络-主机的两级地址结构很快就被证明不够用。在1984年，增加了第三级叫做”subnet“。Subnet可以有任意的长度，并且由一个32bit的网络掩码（netmask）确定。要查看一个地址是否属于一个subnet，将地址与网络掩码进行与操作，结果如果等于subnet，那么地址属于subnet。网络掩码的唯一的限制是bit1必须连续出现在前半部分，bit0必须连续出现在后半部分。

在1990年代早期，IPv4地址就开始用尽了。随后，IETF发现将地址按照分类划分是低效的，所以部署了CIDR（发音成cider，也就是网络地址可以是任意长度）。这使得路由表的尺寸呈爆炸增长，因为越来越多的组织使用了非连续的C类地址（注，也就是 /24长度的CIDR）。在实际使用中，A类地址很难从IANA（Internet Address Number Authority）申请到，因为它有太多的主机地址（2^24个）。而C类地址只有256个主机地址，通常又不够用。所以B类地址被用的最多，但是B类地址只有2^14=16384个，所以B类地址很快就被用光了。

CIDR可以优化通用的场景。通常来说，大部分组织需要使用最多几千个地址，不用分配一个B类地址，几个C类地址就足够了。如果这些C类地址可以是连续的，就可以减少路由表的尺寸，因为router会基于IP地址前缀汇聚路由。我们之后在讨论路由协议的时候会讨论路由表的汇聚。

### 3.2 分片和聚合

不同的网络并不总是有相同的MTU（Maximum Transmission Unit）。当一个IP gateway收到一个packet，并且需要转发到一个有着更小MTU，且MTU小于packet大小的网络时，它有以下选择：

1. 将packet丢弃。实际上，如果发送端在IP header中能设置了不要分片，IP规定就是丢弃packet。丢包之后，gateway会想发送端发送一个基于ICMP协议的错误消息。
2. 将packet分片。IPv4的默认行为是会将packet分片到MTU大小，并将每个分片发送到目的端。在IP header中包含了packet ID和offset，这样接收端可以根据这些信息重新组装分片。

### 3.3 Time-to-live（TTL）

为了避免packet陷入无尽的循环，IP header中有一个TTL字段。它通常会在每个router减一，一旦当TTL等于0，packet会被丢弃。

### 3.4 Type-of-service（TOS）

IP header中有8bit的TOS字段，router可以根据这个字段来区别对待packet。TOS现在并没有很多实用了，不过我们之后会看到DSCP是如何使用这个字段。

### 3.5 Protocol

为了将收到的packet解析到更高的协议栈层（通常是传输层），IP header中会包含8个bit表明下一层的协议类型。

### 3.6 Header Checksum

16bit的校验和，以判断header是否被破坏了。

### 3.7 IP options

IP协议使得节点可以在header中增加option。各种option被定义了，但是鲜有人用，即使有些option是有用的，因为基于现代router的设计方式，在快速路径处理IP option对于高速router来说是个代价很高的操作。大多数的IP option是为了让终端主机使用，但是IPv4协议强制了所有的router处理所有的option，即使router需要做的也只是忽略它们。这最终使得router变得很慢，导致option不被人使用。现在的工程实践是避免使用option，并且router会查看传输层header（例如TCP/UDP 端口号，基于5元组的各种算法都需要用到传出层端口号），这些传输层字段都在固定的位置，只需要很少的解析。

## 4. 今天的TCP/IP: TCP

### 4.1 问题：一个尽力而为的网络

一个尽力而为（best-effort）的网络可以很大程度的简化网络的内部设计，但是意味着时不时的从发送端送出的packet不能到达接收端。TCP解决了3个问题：

1. 由于拥塞和包损坏引起的丢包
2. 包延时是变化的
3. 包乱序，通常由终端主机间有多条路径或者是router的实现有问题引起的

很多应用程序，包括文件传输，Web等，需要可靠的数据传输，以及接收端能按照发送端发出的顺序接收数据。这些应用程序可以从TCP获得收益。

### 4.2 TCP服务模型

TCP服务模型是一个顺序的，可靠的，双向的，字节流抽象。它并不是将datagram作为最小单元，而是将字节作为可靠性的基础。TCP的抽象是在两个主机（实际上是在两个接口）之间的数据传输。双向的是指，一个连接可以处理双向的可靠数据流。

通常来说，可靠传输协议可以使用至少一种下面的技术，在丢包时达到可靠性（注，[详见](l0-background-single-link-communication.md#5.-cuo-wu-hui-fu)）：

1. FEC（Forward Error Correction）
2. ARQ（Automatic Repeat Request）

在TCP中，接收端会定期的通过ACK提示发送端它收到了什么样的数据。

> 现在的TCP协议总，每当接收端收到了一个datagram，它会采用一个叫做delayed ACK的策略，如果持续的有数据流，这个策略会每2个datagram回一个ACK，不管怎么样，至少要在500ms回复一个ACK。

TCP的ACK是累积的，举个例子下面的字节序列：

![](<.gitbook/assets/image (3).png>)

在接收端会触发接收端在收到每个datagram时回复下面的ACK：

**1001           1701           3001           4001           4577**

每个ACK都会确认，目前为止在序列中收到的所有字节数（注，比如第二个ACK确认了1700个字节），并告诉发送端自己期望收到的下一个字节数（注，所以ACK的是1700 + 1 = 1701）。

每个TCP的ACK中都会包含一个接收端的窗口，以告诉发送端当前自己的socket buffer中还有多少可用的空间。这在端到端的流控（flow-control）中是有用的。但是这个不用跟TCP的拥塞控制（congestion control）弄混了，拥塞控制是处理网络中带宽资源竞争的方式。流控只会确保发送端在任何时候都不会使得接收端过载（你会看到流控比拥塞控制简单的多）。

当丢包时，TCP有两种形式的重传：时间驱动（timer-driven）重传和数据驱动（data-driven）重传。前者依赖预估一个连接的RTT（round-trip time）来是设置一个超时时间，如果ACK在发送TCP segment之后经过超时时间还没收到，那么这个TCP segment会重传。后者依赖丢包之后的 其他数据能够成功的被接收到，进而让接收端触发一个packet recovery，而不用等待超时时间。

### 4.3 TCP的定时器们

为了完成重传，发送端需要知道什么时候发生了丢包。如果发送端经过一段时间没有收到ACK，它会假设packet丢失了并且重传packet。现在的问题是发送端究竟要等多久？

这里的超时时间依赖什么因素呢？很明显，它应该依赖TCP连接的RTT。所以发送端需要预估RTT，它是通过监控发送一个packet和收到ACK的时间差来获取数据。它会获取多个时间差并求平均。这里有很多中方法，TCP选用的是一种叫做EWMA（Exponential Weighted Moving Average）的简单方法。这个方法如下计算：

$$
srtt = a * r + (1-a)srtt
$$

这里r是当前采样的时间差，srtt是预估的RTT。为了计算更高效，a=1/8，因为这样可以通过bit移位来完成计算。

我们现在知道如何获取RTT，那如何用RTT来设置重传超时呢？（RTO: retransmission timeout）一种古老的办法是让RTO等于RTT的倍数，例如等于RTT的2倍。实际上，原始的TCP规范RFC793里面用的就是这种方法。不幸的是，这种简单的方法并不能避免虚假重传（Spurious retransmissions）。虚假重传是指packet还在传输的过程中，但是却被发送端认为已经丢失。这可能会导致网络拥塞，因为健壮性原则中的[保守发送](l2-the-internetworking-problem.md#jian-zhuang-xing-yuan-ze)被打破了。

简单的修复方法是使得RTO等于平均值和标准方差的函数，这样可以使得虚假重传的可能性大大降低。

$$
RTO = srtt + 4 * rttvar
$$

rttvar是RTT的平均线性偏差，它按照如下方式计算

$$
rttvar = y * dev + (1-y) * rttvar
$$

其中dev = |r-srtt|， y = 1/4。

问题还没完。TCP还有retransmission ambiguity的问题。当一个被重传了packet的ACK被收到时，发送端怎么计算RTT，使用最初的packet的时间还是用重传packet的时间？这看起来似乎微不足道，但是实际上很严重，因为RTT的预估可以变得毫无意义，并且会影响到吞吐。这个问题的解决方法也很简单，计算RTT时直接忽略有重传的packet。

现代的避免retransmission ambiguity的方法是使用TCP的timestamp option。大部分好的TCP实现都遵从了RFC1323的建议，使用了timestamp option。在这个option中，发送端用8个字节（4个字节记录秒，4个字节记录微秒）以记录当前TCP segment的时间。接收端，会在ACK中，直接返回对应的timestamp option中的值。发送端在接收到ACK之后，可以用当前时间减去ACK中的时间以获取RTT。所以现在是否发生了重传并不重要。

另一个重要的问题是当达到重传超时时，该做什么？很明显，因为TCP是一个”完全可靠“的终端协议，发送端需要重传packet。但是TCP并没有按照相同的频率重传，它采用了一种避免竞争的方式，具体来说就是exponential backoff的机制来更新重传计数器。

有关timeout最后一个需要注意的点是它在实际中非常的保守。TCP的重传计数器通常来说（但并不是所有情况）是粗粒度的，粒度是500或者200毫秒。这就是为什么虚假重传在现代TCP中很少发生的原因，同时也是为什么在下载的时候，一旦超时重传发生了，用户可以很容易的察觉到。

### 4.4 快速重传

超时重传的代价很高（它牺牲了TCP连接的带宽，尽管它很有必要，因为它可以在极端拥塞的情况下确保发送端回退），所以需要探讨其他的重传策略来降低这里的代价。这样的重传策略被称为数据驱动重传。回到之前的例子，假设TCP发送下面的字节序列：

![](<.gitbook/assets/image (3).png>)

但是对应的ACK却是：

![](<.gitbook/assets/image (6).png>)

很明显，重复的ACK表明一些奇怪的事情正在发生，因为在正常情况下，ACK中的序号应该单调递增。在TCP传输过程中的重复ACK可能有以下原因：

1. 接收窗口更新。当接收端发现自己的socket buffer有更多的空间时（比如应用程序从socket buffer读取了一些数据），尽管发送端没有发送新的数据，接收端会通过ACK发送窗口更新到发送端。
2. 丢包。
3. 包乱序。例如当datagram 1701-2500因为走了不同的网络路径，晚于其他的packet才到达接收端，先到达的packet，例如2501:3000，只能触发接收端返回ACK 1701。

非窗口更新的重复的ACK被称为dupack。TCP使用了一个简单的方法来区分丢包和包乱序：如果发送端看到了一个ACK确认的segment超过三个之前的segment，那么发送端认为之前segment丢包了。
